from keras.models import load_model
import cv2
import numpy as np
import time
import os
import threading
import pyodbc
from datetime import datetime


def load_env(path=".env"):
    """Simple .env file reader."""
    if not os.path.exists(path):
        return
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            key, val = line.split("=", 1)
            os.environ.setdefault(key.strip(), val.strip())

load_env()

DB_SERVER = os.getenv("DB_SERVER", "")
DB_DATABASE = os.getenv("DB_DATABASE", "")
DB_USERNAME = os.getenv("DB_USERNAME", "")
DB_PASSWORD = os.getenv("DB_PASSWORD", "")
ROI_FILE = os.getenv("ROI_FILE", "ROI_MESAS.txt")

# Configurações das câmeras
urls_rtsp = [
    'rtsp://10.8.104.23/streaming/channels/1',
    'rtsp://10.8.104.28/streaming/channels/1',
    'rtsp://10.8.104.38/streaming/channels/1',
    'rtsp://10.8.104.48/streaming/channels/1',
    'rtsp://root:C@meras5522@10.8.107.50/axis-media/media.amp?videocodec=h264',
    'rtsp://root:C@meras5522@10.8.105.37/axis-media/media.amp?videocodec=h264'
]

# Carregar ROIs de um arquivo de texto
rois = []
with open(ROI_FILE, 'r') as arquivo:
    for linha in arquivo:
        pontos = linha.strip().split(';')
        roi = [tuple(map(int, ponto.split(','))) for ponto in pontos]
        rois.append(np.array(roi, dtype=np.int32))

# Carregar o modelo e os rótulos
model = load_model("keras_Model.h5", compile=False)
class_names = [line.strip() for line in open("labels.txt", "r").readlines()]

# Configurações da tela de saída
screen_height = 600
screen_width = 1200
output_screen = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)

def processar_frame(frame, roi, index):
    # Desenhar o ROI no frame original
    cv2.polylines(frame, [roi], isClosed=True, color=(0, 255, 0), thickness=2)
    
    # Preparar o ROI para previsão
    mask = np.zeros_like(frame)
    cv2.fillPoly(mask, [roi], (255, 255, 255))
    roi_frame = cv2.bitwise_and(frame, mask)
    x, y, w, h = cv2.boundingRect(roi)
    image = cv2.resize(roi_frame[y:y+h, x:x+w], (224, 224), interpolation=cv2.INTER_AREA)
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)
    image /= 127.5
    image -= 1.0

    # Realizar previsão
    prediction = model.predict(image)
    class_name = class_names[np.argmax(prediction)]
    confidence_score = np.max(prediction)

    # Exibir os resultados da previsão
    font_scale = h / 200  # Ajuste conforme necessário
    if index>3:
        font_scale = h / 150  # Ajuste conforme necessário
    font_thickness = 2 #max(1, int(font_scale * 3))
    text = f"{class_name}"# - {confidence_score:.2f}"
    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]

    text_position = (max(5, x - 100), max(20, y - 10))  # Evitar que o texto saia do frame
    #cv2.putText(frame, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
    
        # Desenhar retângulo preto como fundo do texto
    cv2.rectangle(frame, (text_position[0], text_position[1] - text_size[1] - 3),
                  (text_position[0] + text_size[0], text_position[1]), (0, 0, 0), -1)

    # Exibir os resultados da previsão com o texto sobre o retângulo preto
    cv2.putText(frame, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), font_thickness)

    return class_name, confidence_score, frame


def update_output_screen(frame, index):
    rows = 2
    cols = 3
    tile_w = screen_width // cols
    tile_h = screen_height // rows
    position_x = (index % cols) * tile_w
    position_y = (index // cols) * tile_h
    resized_frame = cv2.resize(frame, (tile_w, tile_h))
    output_screen[position_y:position_y + tile_h, position_x:position_x + tile_w] = resized_frame

def camera_worker(index, url, roi, cursor, stop_event, lock):
    cap = cv2.VideoCapture(url)
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue
        class_name, confidence, processed = processar_frame(frame, roi, index)
        with lock:
            update_output_screen(processed, index)
        timestamp = datetime.now()
        data_to_insert = (timestamp, index + 1, class_name, float(confidence))
        cursor.execute(
            "INSERT INTO detections (timestamp, roi_number, class_name, confidence_score) VALUES (?, ?, ?, ?)",
            data_to_insert,
        )
        cursor.commit()
    cap.release()


def main():
    with pyodbc.connect(
        f"DRIVER={{SQL Server}};SERVER={DB_SERVER};DATABASE={DB_DATABASE};UID={DB_USERNAME};PWD={DB_PASSWORD}"
    ) as cnxn:
        cursor = cnxn.cursor()
        stop_event = threading.Event()
        lock = threading.Lock()
        threads = []

        for index, url in enumerate(urls_rtsp):
            t = threading.Thread(
                target=camera_worker,
                args=(index, url, rois[index], cursor, stop_event, lock),
                daemon=True,
            )
            t.start()
            threads.append(t)

        while True:
            with lock:
                display = output_screen.copy()
            cv2.imshow("Analise de Cameras", display)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                stop_event.set()
                break

        for t in threads:
            t.join()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
